{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48827b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "171f86de",
   "metadata": {},
   "source": [
    "Name: nltk\n",
    "Version: 3.7\n",
    "Summary: Natural Language Toolkit\n",
    "Home-page: https://www.nltk.org/\n",
    "Author: NLTK Team\n",
    "Author-email: nltk.team@gmail.com\n",
    "License: Apache License, Version 2.0\n",
    "Location: c:\\users\\krlozz\\anaconda3\\lib\\site-packages\n",
    "Requires: click, joblib, regex, tqdm\n",
    "Required-by: textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1ef8a",
   "metadata": {},
   "source": [
    "# Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480cac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff525871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Krlozz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Krlozz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Krlozz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88b16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) | set(stopwords.words('spanish'))\n",
    "caracteres_especiales = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc04707",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolos_adicionales = ['±', '½', '‰', '„', '“', '³', '¼', '»', 'º', '´',\n",
    "                        'ℝ', 'ℕ', 'ℚ', 'ℂ', 'ℤ', 'π', 'α', 'β', 'γ', 'δ',\n",
    "                        'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'µ', 'ν', 'ξ',\n",
    "                        'ο', 'π', 'ρ', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω', \n",
    "                        'ℓ', 'ϵ', 'ʽ', 'ʼ', 'œ', 'ʻ', 'ς', 'ﬁ', 'ﬂ', '\\n', '\\r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f748a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteres_especiales.update(simbolos_adicionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e791bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    def remover_tildes(s):\n",
    "        normalized = unicodedata.normalize('NFD', s)\n",
    "        return ''.join(\n",
    "            c for c in normalized\n",
    "            if unicodedata.category(c) != 'Mn' and\n",
    "            not (ord(c) >= 768 and ord(c) <= 879)\n",
    "        ).replace('ŉ', 'n')\n",
    "    \n",
    "    def procesar_especiales(palabra):\n",
    "        if palabra.startswith('@') or palabra.startswith('#'):\n",
    "            contenido = palabra[1:]\n",
    "            if contenido.isalpha() and len(contenido) > 2:\n",
    "                return contenido\n",
    "            return None\n",
    "        if not palabra.isalpha() or len(palabra) <= 2:\n",
    "            return None\n",
    "        return palabra\n",
    "    \n",
    "    texto = texto.replace('ñ', 'ni').replace('\\n', ' ').replace('\\r', ' ').replace('-', ' ')\n",
    "    \n",
    "    palabras = tweet_tokenizer.tokenize(texto)\n",
    "    palabras_procesadas = [\n",
    "        procesar_especiales(remover_tildes(palabra.lower()))\n",
    "        for palabra in palabras\n",
    "        if palabra.lower() not in stop_words and \n",
    "           len(palabra) > 2 and\n",
    "           not any(char.isdigit() for char in palabra)\n",
    "    ]\n",
    "    \n",
    "    palabras_procesadas = [palabra for palabra in palabras_procesadas if palabra is not None]\n",
    "    \n",
    "    palabras_sin_especiales = [\n",
    "        ''.join(caracter for caracter in palabra if caracter not in caracteres_especiales)\n",
    "        for palabra in palabras_procesadas\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(palabra.strip() for palabra in palabras_sin_especiales if palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fcc2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test función\n",
    "frase = \"Este câsa-câsa íno ŉationalisation Î¼atm caí es       un 0.1Î¼gL-1  2023b 61472 #20b #numero #μς \\n10% %ejemplo Pingüino de cómo la función debe limpiar y procesar el texto correctamente, mañana. Any facts that might be perceived as a possible conflict of interest of the author(s) must be disclosed in the paper prior to submission.(Test), ¿paper? and ¡letter! XsD @Hashtag #number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e76b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Este câsa-câsa íno ŉationalisation Î¼atm caí es       un 0.1Î¼gL-1  2023b 61472 #20b #numero #μς \\n10% %ejemplo Pingüino de cómo la función debe limpiar y procesar el texto correctamente, mañana. Any facts that might be perceived as a possible conflict of interest of the author(s) must be disclosed in the paper prior to submission.(Test), ¿paper? and ¡letter! XsD @Hashtag #number'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eefb920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_limpio = limpiar_texto(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a8209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casa casa ino nationalisation atm cai numero ejemplo pinguino como funcion debe limpiar procesar texto correctamente maniana facts might perceived possible conflict interest author must disclosed paper prior submission test paper letter xsd hashtag number\n"
     ]
    }
   ],
   "source": [
    "print(texto_limpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc47cc",
   "metadata": {},
   "source": [
    "# Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba939bca",
   "metadata": {},
   "source": [
    "## articles clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762fd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_path = 'C:/Users/Krlozz/Documents/Tesis/data_JA/articles_v2.csv'\n",
    "articles_df = pd.read_csv(articles_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f72b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        85133492759\n",
       "1        85133293730\n",
       "2        85132518705\n",
       "3        85112575431\n",
       "4        85109263966\n",
       "            ...     \n",
       "39946    33646049406\n",
       "39947    77957209355\n",
       "39948    84941812731\n",
       "39949    84944669127\n",
       "39950    84944670009\n",
       "Name: identifier, Length: 39951, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df[\"identifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf014531",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.rename(columns={'identifier': 'id_article'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e491c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['title'] = articles_df['title'].fillna('').apply(limpiar_texto)\n",
    "articles_df['abstract'] = articles_df['abstract'].fillna('').apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f20b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = articles_df[(articles_df['abstract'] != '') & (articles_df['abstract'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653121d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df[['id_article', 'title', 'abstract']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee23133",
   "metadata": {},
   "source": [
    "## keywords clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07facf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_path = 'C:/Users/Krlozz/Documents/Tesis/data_JA/articles_author_keywords.csv'\n",
    "keywords_df = pd.read_csv(keywords_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85a1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Audio signals design process\n",
       "1         Experimental design processes\n",
       "2                      Fictional spaces\n",
       "3              Sound and changing forms\n",
       "4               Facility layout problem\n",
       "                      ...              \n",
       "162824                       Solanaceae\n",
       "162825              Solanum pseudoquina\n",
       "162826            stereoidal alkaloids.\n",
       "162827                   Endemic goiter\n",
       "162828                    Thyroglobulin\n",
       "Name: author_keyword, Length: 162829, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df[\"author_keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac43e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df['cleaned_keywords'] = keywords_df['author_keyword'].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd72bc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          audio signals design process\n",
       "1         experimental design processes\n",
       "2                      fictional spaces\n",
       "3                  sound changing forms\n",
       "4               facility layout problem\n",
       "                      ...              \n",
       "162824                       solanaceae\n",
       "162825              solanum pseudoquina\n",
       "162826             stereoidal alkaloids\n",
       "162827                   endemic goiter\n",
       "162828                    thyroglobulin\n",
       "Name: cleaned_keywords, Length: 162829, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df['cleaned_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b6742cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_count = keywords_df.groupby('article_id')['cleaned_keywords'].agg(['count', lambda x: ', '.join(x)])\n",
    "keywords_count.rename(columns={'count': 'num_keywords', '<lambda_0>': 'keywords'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e8bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.merge(keywords_count, how='left', left_on='id_article', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a9d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores NaN en num_keywords\n",
    "unique_num_keywords = cleaned_df['num_keywords'].unique()\n",
    "value_counts = cleaned_df['num_keywords'].value_counts(dropna=False)\n",
    "most_frequent_value = value_counts.idxmax()\n",
    "cleaned_df['num_keywords'].fillna(most_frequent_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c444b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_articles = 'C:/Users/Krlozz/Documents/Tesis/TesisFinal/ProcessedData/article_clean.csv'\n",
    "cleaned_df.to_csv(output_articles, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2187c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
